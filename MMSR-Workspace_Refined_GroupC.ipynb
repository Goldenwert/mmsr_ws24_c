{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e48624f-c80b-496f-b93c-1da1b155bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame from 'data/id_information_mmsr.tsv' with shape: (5148, 4)\n",
      "Loaded DataFrame from 'data/id_genres_mmsr.tsv' with shape: (5148, 2)\n",
      "Loaded DataFrame from 'data/id_metadata_mmsr.tsv' with shape: (5148, 11)\n",
      "\n",
      "Metadata DataFrame Columns:\n",
      "['id', 'spotify_id', 'popularity', 'release', 'danceability', 'energy', 'key', 'mode', 'valence', 'tempo', 'duration_ms']\n",
      "Loaded DataFrame from 'data/id_tags_dict.tsv' with shape: (5149, 2)\n",
      "Loaded DataFrame from 'data/id_lyrics_tf-idf_mmsr.tsv' with shape: (5148, 1001)\n",
      "Renamed TF-IDF feature columns to prevent conflicts.\n",
      "Loaded DataFrame from 'data/id_lyrics_bert_mmsr.tsv' with shape: (5148, 769)\n",
      "Renamed BERT feature columns to prevent conflicts.\n",
      "Loaded DataFrame from 'data/id_mfcc_bow_mmsr.tsv' with shape: (5148, 501)\n",
      "Renamed MFCC Bag-of-Words feature columns to prevent conflicts.\n",
      "Loaded DataFrame from 'data/id_blf_spectralcontrast_mmsr.tsv' with shape: (5148, 801)\n",
      "Renamed Spectral Contrast feature columns to prevent conflicts.\n",
      "Loaded DataFrame from 'data/id_vgg19_mmsr.tsv' with shape: (5148, 8193)\n",
      "Renamed VGG19 feature columns to prevent conflicts.\n",
      "Loaded DataFrame from 'data/id_resnet_mmsr.tsv' with shape: (5148, 4097)\n",
      "Renamed ResNet feature columns to prevent conflicts.\n",
      "\n",
      "Merged catalog_df shape after adding Metadata: (5148, 5)\n",
      "\n",
      "'popularity' column successfully added to catalog_df.\n",
      "                 id               artist              song  popularity\n",
      "0  01rMxQv6vhyE1oQX  Against the Current    Chasing Ghosts        41.0\n",
      "1  02ZnlCGZEbkfCDxo        Laura Pausini  Tra Te E Il Mare        36.0\n",
      "2  04OjszRi9rC5BlHC         Grizzly Bear             Knife        45.0\n",
      "3  04iitW3ffa0mhpx3                Ne-Yo  Miss Independent        65.0\n",
      "4  04xUDjAYC14jsHyH           Jawbreaker     Jinx Removing        25.0\n",
      "\n",
      "Number of tracks with missing 'popularity': 0\n",
      "No missing 'popularity' values found.\n",
      "Merged catalog_df shape after merging Genres: (5148, 6)\n",
      "\n",
      "Sample of catalog_df:\n",
      "                 id               artist              song        top_genre\n",
      "0  01rMxQv6vhyE1oQX  Against the Current    Chasing Ghosts          ['rock'\n",
      "1  02ZnlCGZEbkfCDxo        Laura Pausini  Tra Te E Il Mare           ['pop'\n",
      "2  04OjszRi9rC5BlHC         Grizzly Bear             Knife  ['experimental'\n",
      "3  04iitW3ffa0mhpx3                Ne-Yo  Miss Independent           ['pop'\n",
      "4  04xUDjAYC14jsHyH           Jawbreaker     Jinx Removing          ['punk'\n",
      "Merged catalog_df shape after merging Tags: (5148, 8)\n",
      "\n",
      "Sample of catalog_df after merging tags:\n",
      "                 id               artist              song        top_genre  \\\n",
      "0  01rMxQv6vhyE1oQX  Against the Current    Chasing Ghosts          ['rock'   \n",
      "1  02ZnlCGZEbkfCDxo        Laura Pausini  Tra Te E Il Mare           ['pop'   \n",
      "2  04OjszRi9rC5BlHC         Grizzly Bear             Knife  ['experimental'   \n",
      "3  04iitW3ffa0mhpx3                Ne-Yo  Miss Independent           ['pop'   \n",
      "4  04xUDjAYC14jsHyH           Jawbreaker     Jinx Removing          ['punk'   \n",
      "\n",
      "                                                tags  \n",
      "0                      [rock, alternative, pop punk]  \n",
      "1  [italian, laura pausini, pop, female vocalists...  \n",
      "2  [indie, experimental, mellow, folk, lo fi, dre...  \n",
      "3  [rnb, ne yo, pop, r b, male vocalists, miss in...  \n",
      "4  [punk, sad, punk rock, emo, amazing, post hard...  \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. Import Necessary Libraries\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import ast\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# ================================\n",
    "# 2. Define Data Directory and File Paths\n",
    "# ================================\n",
    "\n",
    "DATA_DIR = 'data/'\n",
    "\n",
    "INFORMATION_FILE = DATA_DIR + 'id_information_mmsr.tsv'\n",
    "GENRES_FILE = DATA_DIR + 'id_genres_mmsr.tsv'\n",
    "LYRICS_TFIDF_FILE = DATA_DIR + 'id_lyrics_tf-idf_mmsr.tsv'\n",
    "LYRICS_BERT_FILE = DATA_DIR + 'id_lyrics_bert_mmsr.tsv'\n",
    "MFCC_BOW_FILE = DATA_DIR + 'id_mfcc_bow_mmsr.tsv'\n",
    "SPECTRAL_CONTRAST_FILE = DATA_DIR + 'id_blf_spectralcontrast_mmsr.tsv'\n",
    "VGG19_FILE = DATA_DIR + 'id_vgg19_mmsr.tsv'\n",
    "RESNET_FILE = DATA_DIR + 'id_resnet_mmsr.tsv'\n",
    "TAGS_FILE = DATA_DIR + 'id_tags_dict.tsv'\n",
    "METADATA_FILE = DATA_DIR + 'id_metadata_mmsr.tsv'\n",
    "\n",
    "# ================================\n",
    "# 3. Load Datasets\n",
    "# ================================\n",
    "\n",
    "def load_dataframe(file_path, sep='\\t', header='infer', names=None):\n",
    "    \"\"\"\n",
    "    Utility function to load a TSV file into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=sep, header=header, names=names)\n",
    "        print(f\"Loaded DataFrame from '{file_path}' with shape: {df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        exit(1)\n",
    "\n",
    "# Load Information Dataset\n",
    "information_df = load_dataframe(INFORMATION_FILE)\n",
    "\n",
    "# Load Genres Dataset\n",
    "genres_df = load_dataframe(GENRES_FILE)\n",
    "\n",
    "# Load Metadata Dataset\n",
    "metadata_df = load_dataframe(METADATA_FILE)\n",
    "print(\"\\nMetadata DataFrame Columns:\")\n",
    "print(metadata_df.columns.tolist())\n",
    "\n",
    "# Load Tags Dataset\n",
    "tags_df = load_dataframe(TAGS_FILE, header=None, names=['id', 'tags_str'])\n",
    "\n",
    "# Load Lyrics TF-IDF\n",
    "lyrics_tfidf_df = load_dataframe(LYRICS_TFIDF_FILE)\n",
    "tfidf_cols = [col for col in lyrics_tfidf_df.columns if col != 'id']\n",
    "lyrics_tfidf_df.rename(columns={col: f\"tfidf_{col}\" for col in tfidf_cols}, inplace=True)\n",
    "print(\"Renamed TF-IDF feature columns to prevent conflicts.\")\n",
    "\n",
    "# Load BERT Embeddings\n",
    "bert_df = load_dataframe(LYRICS_BERT_FILE)\n",
    "bert_feature_columns = [col for col in bert_df.columns if col != 'id']\n",
    "bert_df.rename(columns={col: f\"bert_{col}\" for col in bert_feature_columns}, inplace=True)\n",
    "print(\"Renamed BERT feature columns to prevent conflicts.\")\n",
    "\n",
    "# Load MFCC Bag-of-Words\n",
    "mfcc_bow_df = load_dataframe(MFCC_BOW_FILE)\n",
    "mfcc_bow_columns = [col for col in mfcc_bow_df.columns if col != 'id']\n",
    "mfcc_bow_df.rename(columns={col: f\"mfcc_{col}\" for col in mfcc_bow_columns}, inplace=True)\n",
    "print(\"Renamed MFCC Bag-of-Words feature columns to prevent conflicts.\")\n",
    "\n",
    "# Load Spectral Contrast\n",
    "spectral_contrast_df = load_dataframe(SPECTRAL_CONTRAST_FILE)\n",
    "spectral_contrast_columns = [col for col in spectral_contrast_df.columns if col != 'id']\n",
    "spectral_contrast_df.rename(columns={col: f\"spectral_{col}\" for col in spectral_contrast_columns}, inplace=True)\n",
    "print(\"Renamed Spectral Contrast feature columns to prevent conflicts.\")\n",
    "\n",
    "# Load VGG19 Features\n",
    "vgg19_df = load_dataframe(VGG19_FILE)\n",
    "vgg19_feature_columns = [col for col in vgg19_df.columns if col != 'id']\n",
    "vgg19_df.rename(columns={col: f\"vgg19_{col}\" for col in vgg19_feature_columns}, inplace=True)\n",
    "print(\"Renamed VGG19 feature columns to prevent conflicts.\")\n",
    "\n",
    "# Load ResNet Features\n",
    "resnet_df = load_dataframe(RESNET_FILE)\n",
    "resnet_feature_columns = [col for col in resnet_df.columns if col != 'id']\n",
    "resnet_df.rename(columns={col: f\"resnet_{col}\" for col in resnet_feature_columns}, inplace=True)\n",
    "print(\"Renamed ResNet feature columns to prevent conflicts.\")\n",
    "\n",
    "# ================================\n",
    "# 4. Merge and Preprocess DataFrames\n",
    "# ================================\n",
    "\n",
    "# Merge Information and Metadata\n",
    "catalog_df = pd.merge(information_df, metadata_df[['id', 'popularity']], on='id', how='left')\n",
    "print(f\"\\nMerged catalog_df shape after adding Metadata: {catalog_df.shape}\")\n",
    "\n",
    "# Verify 'popularity' Column\n",
    "if 'popularity' in catalog_df.columns:\n",
    "    print(\"\\n'popularity' column successfully added to catalog_df.\")\n",
    "    print(catalog_df[['id', 'artist', 'song', 'popularity']].head())\n",
    "else:\n",
    "    print(\"Error: 'popularity' column is still missing after merging Metadata.\")\n",
    "    exit(1)\n",
    "\n",
    "# Handle Missing 'popularity' Values\n",
    "missing_popularity = catalog_df['popularity'].isnull().sum()\n",
    "print(f\"\\nNumber of tracks with missing 'popularity': {missing_popularity}\")\n",
    "\n",
    "if missing_popularity > 0:\n",
    "    # Drop tracks with missing 'popularity'\n",
    "    initial_size = len(catalog_df)\n",
    "    catalog_df = catalog_df.dropna(subset=['popularity']).reset_index(drop=True)\n",
    "    final_size = len(catalog_df)\n",
    "    dropped = initial_size - final_size\n",
    "    print(f\"Dropped {dropped} tracks due to missing 'popularity' values.\")\n",
    "else:\n",
    "    print(\"No missing 'popularity' values found.\")\n",
    "\n",
    "# Function to parse genres from string to list\n",
    "def parse_genres(genre_str):\n",
    "    if pd.isnull(genre_str):\n",
    "        return []\n",
    "    return [genre.strip() for genre in genre_str.split(',')]\n",
    "\n",
    "# Apply parsing to 'genre' column\n",
    "genres_df['genre'] = genres_df['genre'].apply(parse_genres)\n",
    "\n",
    "# Merge Information and Genres to update catalog_df\n",
    "catalog_df = pd.merge(catalog_df, genres_df, on='id', how='left')\n",
    "print(f\"Merged catalog_df shape after merging Genres: {catalog_df.shape}\")\n",
    "\n",
    "# Handle missing genres by assigning an empty list\n",
    "catalog_df['genre'] = catalog_df['genre'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Function to get the top genre from the genre list\n",
    "def get_top_genre(genres_list):\n",
    "    if not genres_list:\n",
    "        return None\n",
    "    return genres_list[0]  # Modify as needed\n",
    "\n",
    "# Apply the function to determine the top genre\n",
    "catalog_df['top_genre'] = catalog_df['genre'].apply(get_top_genre)\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample of catalog_df:\")\n",
    "print(catalog_df[['id', 'artist', 'song', 'top_genre']].head())\n",
    "\n",
    "# Merge Tags into catalog_df\n",
    "def parse_tags(tag_str):\n",
    "    if pd.isnull(tag_str):\n",
    "        return []\n",
    "    try:\n",
    "        tags_dict = ast.literal_eval(tag_str)\n",
    "        if isinstance(tags_dict, dict):\n",
    "            return list(tags_dict.keys())\n",
    "        else:\n",
    "            return []\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "tags_df['tags'] = tags_df['tags_str'].apply(parse_tags)\n",
    "\n",
    "catalog_df = pd.merge(catalog_df, tags_df[['id', 'tags']], on='id', how='left')\n",
    "print(f\"Merged catalog_df shape after merging Tags: {catalog_df.shape}\")\n",
    "\n",
    "# Handle missing tags by assigning an empty list\n",
    "catalog_df['tags'] = catalog_df['tags'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Display sample data to verify\n",
    "print(\"\\nSample of catalog_df after merging tags:\")\n",
    "print(catalog_df[['id', 'artist', 'song', 'top_genre', 'tags']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47b1109-c28a-4323-9e97-127abcda0b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Lyrics TF-IDF DataFrame...\n",
      "Merged catalog_df shape after adding TF-IDF features: (5148, 1008)\n",
      "Number of TF-IDF feature columns: 1000\n",
      "All TF-IDF columns are present in catalog_df.\n",
      "Total missing TF-IDF values: 0\n",
      "No missing TF-IDF values found.\n",
      "\n",
      "TF-IDF Matrix Shape: (5148, 1000)\n",
      "\n",
      "Processing BERT Embeddings...\n",
      "Merged catalog_df shape after adding BERT embeddings: (5148, 1776)\n",
      "No missing BERT embeddings found.\n",
      "BERT Matrix Shape: (5148, 768)\n",
      "\n",
      "Processing Audio Features (MFCC and Spectral Contrast)...\n",
      "Merged catalog_df shape after adding Audio features: (5148, 3076)\n",
      "Total missing Audio feature values: 0\n",
      "No missing Audio features found.\n",
      "\n",
      "MFCC Bag-of-Words Matrix Shape: (5148, 500)\n",
      "Spectral Contrast Matrix Shape: (5148, 800)\n",
      "\n",
      "Processing VGG19 Features...\n",
      "Merged catalog_df shape after adding VGG19 features: (5148, 11268)\n",
      "No missing VGG19 features found.\n",
      "VGG19 Matrix Shape: (5148, 8192)\n",
      "\n",
      "Processing ResNet Features...\n",
      "Merged catalog_df shape after adding ResNet features: (5148, 15364)\n",
      "No missing ResNet features found.\n",
      "ResNet Matrix Shape: (5148, 4096)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5. Process and Integrate TF-IDF Features\n",
    "# ================================\n",
    "\n",
    "# Check and load Lyrics TF-IDF DataFrame\n",
    "if 'tfidf_id' in lyrics_tfidf_df.columns or 'id' in lyrics_tfidf_df.columns:\n",
    "    print(\"\\nProcessing Lyrics TF-IDF DataFrame...\")\n",
    "else:\n",
    "    print(\"Error: Unexpected columns in Lyrics TF-IDF DataFrame.\")\n",
    "    exit(1)\n",
    "\n",
    "# Merge TF-IDF with catalog_df\n",
    "catalog_df = pd.merge(catalog_df, lyrics_tfidf_df, on='id', how='left')\n",
    "print(f\"Merged catalog_df shape after adding TF-IDF features: {catalog_df.shape}\")\n",
    "\n",
    "# Identify TF-IDF feature columns (exclude 'id')\n",
    "tfidf_feature_columns = [col for col in lyrics_tfidf_df.columns if col != 'id']\n",
    "print(f\"Number of TF-IDF feature columns: {len(tfidf_feature_columns)}\")\n",
    "\n",
    "# Check for missing TF-IDF columns\n",
    "missing_tfidf_columns = [col for col in tfidf_feature_columns if col not in catalog_df.columns]\n",
    "if missing_tfidf_columns:\n",
    "    print(f\"Missing TF-IDF columns in catalog_df: {missing_tfidf_columns[:10]}\")\n",
    "else:\n",
    "    print(\"All TF-IDF columns are present in catalog_df.\")\n",
    "\n",
    "# Check for missing values in TF-IDF features\n",
    "missing_tfidf = catalog_df[tfidf_feature_columns].isnull().sum().sum()\n",
    "print(f\"Total missing TF-IDF values: {missing_tfidf}\")\n",
    "\n",
    "if missing_tfidf > 0:\n",
    "    # Drop tracks with missing TF-IDF features\n",
    "    initial_size = len(catalog_df)\n",
    "    catalog_df = catalog_df.dropna(subset=tfidf_feature_columns).reset_index(drop=True)\n",
    "    final_size = len(catalog_df)\n",
    "    dropped = initial_size - final_size\n",
    "    print(f\"Dropped {dropped} tracks due to missing TF-IDF features.\")\n",
    "else:\n",
    "    print(\"No missing TF-IDF values found.\")\n",
    "\n",
    "# Extract TF-IDF features\n",
    "tfidf_features = catalog_df[tfidf_feature_columns].values\n",
    "\n",
    "# Normalize TF-IDF features\n",
    "tfidf_matrix = normalize(tfidf_features, norm='l2')\n",
    "\n",
    "# Convert to sparse matrix for efficiency\n",
    "tfidf_matrix = csr_matrix(tfidf_matrix)\n",
    "print(f\"\\nTF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# ================================\n",
    "# 6. Process and Integrate BERT Features\n",
    "# ================================\n",
    "\n",
    "print(\"\\nProcessing BERT Embeddings...\")\n",
    "\n",
    "# Merge BERT embeddings with catalog_df\n",
    "catalog_df = pd.merge(catalog_df, bert_df, on='id', how='left')\n",
    "print(f\"Merged catalog_df shape after adding BERT embeddings: {catalog_df.shape}\")\n",
    "\n",
    "# Handle missing BERT embeddings by dropping tracks with missing BERT features\n",
    "bert_feature_columns = [f\"bert_{col}\" for col in bert_feature_columns]  # Updated after renaming\n",
    "missing_bert = catalog_df[bert_feature_columns].isnull().sum().sum()\n",
    "if missing_bert > 0:\n",
    "    initial_size = len(catalog_df)\n",
    "    catalog_df = catalog_df.dropna(subset=bert_feature_columns).reset_index(drop=True)\n",
    "    final_size = len(catalog_df)\n",
    "    dropped = initial_size - final_size\n",
    "    print(f\"Dropped {dropped} tracks due to missing BERT embeddings.\")\n",
    "else:\n",
    "    print(\"No missing BERT embeddings found.\")\n",
    "\n",
    "# Extract BERT features\n",
    "bert_features = catalog_df[bert_feature_columns].values\n",
    "\n",
    "# Convert to sparse matrix for efficiency (optional: depending on similarity measure)\n",
    "bert_matrix = csr_matrix(bert_features)\n",
    "print(f\"BERT Matrix Shape: {bert_matrix.shape}\")\n",
    "\n",
    "# ================================\n",
    "# 7. Process and Integrate Audio Features (MFCC and Spectral Contrast)\n",
    "# ================================\n",
    "\n",
    "print(\"\\nProcessing Audio Features (MFCC and Spectral Contrast)...\")\n",
    "\n",
    "# Merge MFCC and Spectral Contrast with catalog_df\n",
    "catalog_df = pd.merge(catalog_df, mfcc_bow_df, on='id', how='left')\n",
    "catalog_df = pd.merge(catalog_df, spectral_contrast_df, on='id', how='left')\n",
    "print(f\"Merged catalog_df shape after adding Audio features: {catalog_df.shape}\")\n",
    "\n",
    "# Handle missing Audio features by dropping tracks with missing audio features\n",
    "audio_feature_columns = [f\"mfcc_{col}\" for col in mfcc_bow_columns] + [f\"spectral_{col}\" for col in spectral_contrast_columns]\n",
    "missing_audio = catalog_df[audio_feature_columns].isnull().sum().sum()\n",
    "print(f\"Total missing Audio feature values: {missing_audio}\")\n",
    "\n",
    "if missing_audio > 0:\n",
    "    initial_size = len(catalog_df)\n",
    "    catalog_df = catalog_df.dropna(subset=audio_feature_columns).reset_index(drop=True)\n",
    "    final_size = len(catalog_df)\n",
    "    dropped = initial_size - final_size\n",
    "    print(f\"Dropped {dropped} tracks due to missing Audio features.\")\n",
    "else:\n",
    "    print(\"No missing Audio features found.\")\n",
    "\n",
    "# Extract MFCC features\n",
    "mfcc_bow_features = catalog_df[[f\"mfcc_{col}\" for col in mfcc_bow_columns]].values\n",
    "mfcc_bow_matrix = csr_matrix(mfcc_bow_features)\n",
    "print(f\"\\nMFCC Bag-of-Words Matrix Shape: {mfcc_bow_matrix.shape}\")\n",
    "\n",
    "# Extract Spectral Contrast features\n",
    "spectral_contrast_features = catalog_df[[f\"spectral_{col}\" for col in spectral_contrast_columns]].values\n",
    "spectral_contrast_matrix = csr_matrix(spectral_contrast_features)\n",
    "print(f\"Spectral Contrast Matrix Shape: {spectral_contrast_matrix.shape}\")\n",
    "\n",
    "# ================================\n",
    "# 8. Process and Integrate VGG19 Features\n",
    "# ================================\n",
    "\n",
    "print(\"\\nProcessing VGG19 Features...\")\n",
    "\n",
    "# Merge VGG19 with catalog_df\n",
    "catalog_df = pd.merge(catalog_df, vgg19_df, on='id', how='left')\n",
    "print(f\"Merged catalog_df shape after adding VGG19 features: {catalog_df.shape}\")\n",
    "\n",
    "# Handle missing VGG19 features by dropping tracks with missing VGG19 features\n",
    "vgg19_feature_columns = [f\"vgg19_{col}\" for col in vgg19_feature_columns]  # Updated after renaming\n",
    "missing_vgg19 = catalog_df[vgg19_feature_columns].isnull().sum().sum()\n",
    "if missing_vgg19 > 0:\n",
    "    initial_size = len(catalog_df)\n",
    "    catalog_df = catalog_df.dropna(subset=vgg19_feature_columns).reset_index(drop=True)\n",
    "    final_size = len(catalog_df)\n",
    "    dropped = initial_size - final_size\n",
    "    print(f\"Dropped {dropped} tracks due to missing VGG19 features.\")\n",
    "else:\n",
    "    print(\"No missing VGG19 features found.\")\n",
    "\n",
    "# Extract VGG19 features\n",
    "vgg19_features = catalog_df[vgg19_feature_columns].values\n",
    "vgg19_matrix = csr_matrix(vgg19_features)\n",
    "print(f\"VGG19 Matrix Shape: {vgg19_matrix.shape}\")\n",
    "\n",
    "# ================================\n",
    "# 9. Process and Integrate ResNet Features\n",
    "# ================================\n",
    "\n",
    "print(\"\\nProcessing ResNet Features...\")\n",
    "\n",
    "# Merge ResNet with catalog_df\n",
    "catalog_df = pd.merge(catalog_df, resnet_df, on='id', how='left')\n",
    "print(f\"Merged catalog_df shape after adding ResNet features: {catalog_df.shape}\")\n",
    "\n",
    "# Handle missing ResNet features by dropping tracks with missing ResNet features\n",
    "resnet_feature_columns = [f\"resnet_{col}\" for col in resnet_feature_columns]  # Updated after renaming\n",
    "missing_resnet = catalog_df[resnet_feature_columns].isnull().sum().sum()\n",
    "if missing_resnet > 0:\n",
    "    initial_size = len(catalog_df)\n",
    "    catalog_df = catalog_df.dropna(subset=resnet_feature_columns).reset_index(drop=True)\n",
    "    final_size = len(catalog_df)\n",
    "    dropped = initial_size - final_size\n",
    "    print(f\"Dropped {dropped} tracks due to missing ResNet features.\")\n",
    "else:\n",
    "    print(\"No missing ResNet features found.\")\n",
    "\n",
    "# Extract ResNet features\n",
    "resnet_features = catalog_df[resnet_feature_columns].values\n",
    "resnet_matrix = csr_matrix(resnet_features)\n",
    "print(f\"ResNet Matrix Shape: {resnet_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5abe9ae-cfa8-44b5-927b-33897c0db186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tags: 43845\n",
      "Tag Matrix Shape: (5148, 43845)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 10. Define Retrieval Functions\n",
    "# ================================\n",
    "\n",
    "def random_retrieval(query_track_id, id_to_index=None, feature_matrix=None, track_ids=None, catalog_df=None, N=10):\n",
    "    \"\"\"\n",
    "    Randomly selects N tracks from the catalog, excluding the query track.\n",
    "\n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict, optional): Mapping from track ID to index in feature_matrix (unused).\n",
    "    - feature_matrix (csr_matrix, optional): Feature matrix used by other retrieval functions (unused).\n",
    "    - track_ids (list, optional): List of all track IDs (unused).\n",
    "    - catalog_df (pd.DataFrame): The catalog containing all tracks.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - retrieved_tracks (pd.DataFrame): DataFrame of retrieved tracks.\n",
    "    \"\"\"\n",
    "    if catalog_df is None:\n",
    "        raise ValueError(\"catalog_df must be provided for Random Retrieval.\")\n",
    "    \n",
    "    # Exclude the query track\n",
    "    candidates = catalog_df[catalog_df['id'] != query_track_id]\n",
    "    \n",
    "    # Determine the number of tracks to sample\n",
    "    sample_size = min(N, len(candidates))\n",
    "    \n",
    "    # Randomly sample N tracks\n",
    "    retrieved_tracks = candidates.sample(n=sample_size, replace=False, random_state=random.randint(0, 1000000))\n",
    "    \n",
    "    return retrieved_tracks.reset_index(drop=True)\n",
    "\n",
    "# Define and Initialize tfidf_retrieval function\n",
    "def tfidf_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks most similar to the query track based on TF-IDF cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix.\n",
    "    - feature_matrix (csr_matrix): TF-IDF feature matrix.\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with similarity scores.\n",
    "    \"\"\"\n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    query_index = id_to_index[query_track_id]\n",
    "    query_vector = feature_matrix[query_index]\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, feature_matrix).flatten()\n",
    "\n",
    "    # Exclude the query track\n",
    "    similarities[query_index] = -1\n",
    "\n",
    "    # Get top N indices\n",
    "    top_indices = similarities.argsort()[-N:][::-1]\n",
    "\n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_scores = [similarities[i] for i in top_indices]\n",
    "\n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'similarity': retrieved_scores\n",
    "    })\n",
    "\n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "\n",
    "    return retrieved_tracks_df\n",
    "\n",
    "def bert_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks most similar to the query track based on BERT cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix.\n",
    "    - feature_matrix (csr_matrix): BERT feature matrix.\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with similarity scores.\n",
    "    \"\"\"\n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    query_index = id_to_index[query_track_id]\n",
    "    query_vector = feature_matrix[query_index]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, feature_matrix).flatten()\n",
    "    \n",
    "    # Exclude the query track\n",
    "    similarities[query_index] = -1\n",
    "    \n",
    "    # Get top N indices\n",
    "    top_indices = similarities.argsort()[-N:][::-1]\n",
    "    \n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_scores = [similarities[i] for i in top_indices]\n",
    "    \n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'similarity': retrieved_scores\n",
    "    })\n",
    "    \n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "    \n",
    "    return retrieved_tracks_df\n",
    "\n",
    "def mfcc_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks most similar to the query track based on MFCC Euclidean distance.\n",
    "\n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix.\n",
    "    - feature_matrix (csr_matrix): MFCC Bag-of-Words feature matrix.\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with distance scores.\n",
    "    \"\"\"\n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    query_index = id_to_index[query_track_id]\n",
    "    query_vector = feature_matrix[query_index].toarray()\n",
    "    \n",
    "    # Compute Euclidean distances\n",
    "    # To optimize, use vectorized operations without converting entire matrix to dense\n",
    "    distances = np.linalg.norm(feature_matrix - query_vector, axis=1)\n",
    "    \n",
    "    # Exclude the query track\n",
    "    distances[query_index] = np.inf\n",
    "    \n",
    "    # Get top N indices with smallest distances\n",
    "    top_indices = distances.argsort()[:N]\n",
    "    \n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_distances = distances[top_indices]\n",
    "    \n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'distance': retrieved_distances\n",
    "    })\n",
    "    \n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "    \n",
    "    return retrieved_tracks_df\n",
    "\n",
    "def spectral_contrast_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks most similar to the query track based on Spectral Contrast Cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix.\n",
    "    - feature_matrix (csr_matrix): Spectral Contrast feature matrix.\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with similarity scores.\n",
    "    \"\"\"\n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    query_index = id_to_index[query_track_id]\n",
    "    query_vector = feature_matrix[query_index]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, feature_matrix).flatten()\n",
    "    \n",
    "    # Exclude the query track\n",
    "    similarities[query_index] = -1\n",
    "    \n",
    "    # Get top N indices\n",
    "    top_indices = similarities.argsort()[-N:][::-1]\n",
    "    \n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_scores = [similarities[i] for i in top_indices]\n",
    "    \n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'similarity': retrieved_scores\n",
    "    })\n",
    "    \n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "    \n",
    "    return retrieved_tracks_df\n",
    "\n",
    "def vgg19_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks most similar to the query track based on VGG19 Cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix.\n",
    "    - feature_matrix (csr_matrix): VGG19 feature matrix.\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with similarity scores.\n",
    "    \"\"\"\n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    query_index = id_to_index[query_track_id]\n",
    "    query_vector = feature_matrix[query_index]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, feature_matrix).flatten()\n",
    "    \n",
    "    # Exclude the query track\n",
    "    similarities[query_index] = -1\n",
    "    \n",
    "    # Get top N indices\n",
    "    top_indices = similarities.argsort()[-N:][::-1]\n",
    "    \n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_scores = [similarities[i] for i in top_indices]\n",
    "    \n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'similarity': retrieved_scores\n",
    "    })\n",
    "    \n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "    \n",
    "    return retrieved_tracks_df\n",
    "\n",
    "def resnet_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks most similar to the query track based on ResNet Euclidean distance.\n",
    "\n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix.\n",
    "    - feature_matrix (csr_matrix): ResNet feature matrix.\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with distance scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    query_index = id_to_index[query_track_id]\n",
    "    query_vector = feature_matrix[query_index].toarray()\n",
    "    \n",
    "    # Compute Euclidean distances\n",
    "    # To optimize, use vectorized operations without converting entire matrix to dense\n",
    "    distances = np.linalg.norm(feature_matrix - query_vector, axis=1)\n",
    "    \n",
    "    # Exclude the query track\n",
    "    distances[query_index] = np.inf\n",
    "    \n",
    "    # Get top N indices with smallest distances\n",
    "    top_indices = distances.argsort()[:N]\n",
    "    \n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_distances = distances[top_indices]\n",
    "    \n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'distance': retrieved_distances\n",
    "    })\n",
    "    \n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "    \n",
    "    return retrieved_tracks_df\n",
    "\n",
    "# ================================\n",
    "# 11. Process and Integrate Tag Features\n",
    "# ================================\n",
    "\n",
    "def build_tag_vocabulary(catalog_df):\n",
    "    \"\"\"\n",
    "    Builds a tag vocabulary from the catalog.\n",
    "    \n",
    "    Parameters:\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing 'id' and 'tags'.\n",
    "    \n",
    "    Returns:\n",
    "    - tag_to_index (dict): Mapping from tag to index.\n",
    "    \"\"\"\n",
    "    all_tags = set(tag for tags in catalog_df['tags'] for tag in tags)\n",
    "    tag_to_index = {tag: idx for idx, tag in enumerate(sorted(all_tags))}\n",
    "    return tag_to_index\n",
    "\n",
    "def vectorize_tags(catalog_df, tag_to_index):\n",
    "    \"\"\"\n",
    "    Vectorizes the tags for each track.\n",
    "    \n",
    "    Parameters:\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing 'id' and 'tags'.\n",
    "    - tag_to_index (dict): Mapping from tag to index.\n",
    "    \n",
    "    Returns:\n",
    "    - tag_matrix (csr_matrix): Sparse matrix of tag vectors.\n",
    "    \"\"\"\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    data = []\n",
    "    \n",
    "    for row, tags in enumerate(catalog_df['tags']):\n",
    "        for tag in tags:\n",
    "            if tag in tag_to_index:\n",
    "                col = tag_to_index[tag]\n",
    "                row_indices.append(row)\n",
    "                col_indices.append(col)\n",
    "                data.append(1)  # Assuming binary occurrence; modify if weights are available\n",
    "    \n",
    "    tag_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(len(catalog_df), len(tag_to_index)))\n",
    "    tag_matrix = normalize(tag_matrix, norm='l2')\n",
    "    return tag_matrix\n",
    "\n",
    "# Building Tag Vocabulary\n",
    "tag_to_index = build_tag_vocabulary(catalog_df)\n",
    "print(f\"Total unique tags: {len(tag_to_index)}\")\n",
    "\n",
    "# Vectorizing Tags\n",
    "tag_matrix = vectorize_tags(catalog_df, tag_to_index)\n",
    "print(f\"Tag Matrix Shape: {tag_matrix.shape}\")\n",
    "\n",
    "def tag_based_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks most similar to the query track based on tag similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix.\n",
    "    - feature_matrix (csr_matrix): Tag feature matrix.\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with similarity scores.\n",
    "    \"\"\"\n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    query_index = id_to_index[query_track_id]\n",
    "    query_vector = feature_matrix[query_index]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, feature_matrix).flatten()\n",
    "    \n",
    "    # Exclude the query track\n",
    "    similarities[query_index] = -1\n",
    "    \n",
    "    # Get top N indices\n",
    "    top_indices = similarities.argsort()[-N:][::-1]\n",
    "    \n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_scores = [similarities[i] for i in top_indices]\n",
    "    \n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'similarity': retrieved_scores\n",
    "    })\n",
    "    \n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "    \n",
    "    return retrieved_tracks_df\n",
    "\n",
    "# ================================\n",
    "# 12. Define Fusion Retrievals\n",
    "# ================================\n",
    "\n",
    "def early_fusion_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks using Early Fusion by combining TF-IDF and BERT feature matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix.\n",
    "    - feature_matrix (csr_matrix): Combined feature matrix (TF-IDF + BERT).\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with similarity scores.\n",
    "    \"\"\"\n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    query_index = id_to_index[query_track_id]\n",
    "    query_vector = feature_matrix[query_index]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, feature_matrix).flatten()\n",
    "    \n",
    "    # Exclude the query track\n",
    "    similarities[query_index] = -1\n",
    "    \n",
    "    # Get top N indices\n",
    "    top_indices = similarities.argsort()[-N:][::-1]\n",
    "    \n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_scores = [similarities[i] for i in top_indices]\n",
    "    \n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'similarity': retrieved_scores\n",
    "    })\n",
    "    \n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "    \n",
    "    return retrieved_tracks_df\n",
    "\n",
    "def late_fusion_retrieval(query_track_id, id_to_index, feature_matrix1, feature_matrix2, track_ids, catalog_df, N=10, weight1=0.5, weight2=0.5):\n",
    "    \"\"\"\n",
    "    Retrieves N tracks using Late Fusion by combining MFCC and VGG19 retrieval scores.\n",
    "    \n",
    "    Parameters:\n",
    "    - query_track_id (str): The ID of the query track.\n",
    "    - id_to_index (dict): Mapping from track ID to index in feature_matrix1 and feature_matrix2.\n",
    "    - feature_matrix1 (csr_matrix): MFCC feature matrix.\n",
    "    - feature_matrix2 (csr_matrix): VGG19 feature matrix.\n",
    "    - track_ids (list): List of all track IDs.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing track metadata.\n",
    "    - N (int): Number of tracks to retrieve.\n",
    "    - weight1 (float): Weight for MFCC similarity.\n",
    "    - weight2 (float): Weight for VGG19 similarity.\n",
    "    \n",
    "    Returns:\n",
    "    - retrieved_tracks_df (pd.DataFrame): DataFrame of retrieved tracks with aggregated similarity scores.\n",
    "    \"\"\"\n",
    "    if query_track_id not in id_to_index:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    query_index = id_to_index[query_track_id]\n",
    "    \n",
    "    # Compute cosine similarity for MFCC\n",
    "    query_vector1 = feature_matrix1[query_index]\n",
    "    similarities1 = cosine_similarity(query_vector1, feature_matrix1).flatten()\n",
    "    similarities1[query_index] = -1  # Exclude query\n",
    "    \n",
    "    # Compute cosine similarity for VGG19\n",
    "    query_vector2 = feature_matrix2[query_index]\n",
    "    similarities2 = cosine_similarity(query_vector2, feature_matrix2).flatten()\n",
    "    similarities2[query_index] = -1  # Exclude query\n",
    "    \n",
    "    # Weighted average of similarities\n",
    "    aggregated_similarities = weight1 * similarities1 + weight2 * similarities2\n",
    "    \n",
    "    # Get top N indices\n",
    "    top_indices = aggregated_similarities.argsort()[-N:][::-1]\n",
    "    \n",
    "    retrieved_ids = [track_ids[i] for i in top_indices]\n",
    "    retrieved_scores = [aggregated_similarities[i] for i in top_indices]\n",
    "    \n",
    "    retrieved_tracks_df = pd.DataFrame({\n",
    "        'id': retrieved_ids,\n",
    "        'aggregated_similarity': retrieved_scores\n",
    "    })\n",
    "    \n",
    "    retrieved_tracks_df = pd.merge(retrieved_tracks_df, catalog_df[['id', 'artist', 'song', 'album_name']], on='id', how='left')\n",
    "    \n",
    "    return retrieved_tracks_df\n",
    "\n",
    "# ================================\n",
    "# 13. Define Wrapper Functions for Hybrid Systems\n",
    "# ================================\n",
    "\n",
    "def tag_based_retrieval_wrapper(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    return tag_based_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N)\n",
    "\n",
    "def early_fusion_retrieval_wrapper(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    return early_fusion_retrieval(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N)\n",
    "\n",
    "def late_fusion_retrieval_wrapper(query_track_id, id_to_index, feature_matrix, track_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Wrapper function to perform Late Fusion Retrieval combining MFCC and VGG19.\n",
    "    Assumes 'MFCC Retrieval' and 'VGG19 Retrieval' are in feature_matrices.\n",
    "    \"\"\"\n",
    "    feature_matrix1 = feature_matrices['MFCC Retrieval']\n",
    "    feature_matrix2 = feature_matrices['VGG19 Retrieval']\n",
    "    return late_fusion_retrieval(\n",
    "        query_track_id,\n",
    "        id_to_index,\n",
    "        feature_matrix1,\n",
    "        feature_matrix2,\n",
    "        track_ids,\n",
    "        catalog_df,\n",
    "        N=N,\n",
    "        weight1=0.5,  # Equal weights; adjust as needed\n",
    "        weight2=0.5\n",
    "    )\n",
    "\n",
    "# ================================\n",
    "# 14. Initialize Feature Matrices and Retrieval Systems\n",
    "# ================================\n",
    "\n",
    "# Initialize feature matrices for retrieval functions that require them\n",
    "feature_matrices = {\n",
    "    'TF-IDF Retrieval': tfidf_matrix,\n",
    "    'BERT Retrieval': bert_matrix,\n",
    "    'MFCC Retrieval': mfcc_bow_matrix,\n",
    "    'Spectral Contrast Retrieval': spectral_contrast_matrix,\n",
    "    'VGG19 Retrieval': vgg19_matrix,\n",
    "    'ResNet Retrieval': resnet_matrix,\n",
    "    'Tag-Based Retrieval': tag_matrix,  # New\n",
    "    # 'Early Fusion TF-IDF+BERT Retrieval': early_fusion_retrieval(query_track_id=None, id_to_index=None, feature_matrix=None, track_ids=None, catalog_df=None, N=10)  # Placeholder\n",
    "    # 'Late Fusion MFCC+VGG19 Retrieval' does not require a separate feature matrix as it uses existing ones\n",
    "}\n",
    "\n",
    "# Define all retrieval systems\n",
    "retrieval_systems = {\n",
    "    'TF-IDF Retrieval': tfidf_retrieval,\n",
    "    'Random Retrieval': random_retrieval,\n",
    "    'BERT Retrieval': bert_retrieval,\n",
    "    'MFCC Retrieval': mfcc_retrieval,\n",
    "    'Spectral Contrast Retrieval': spectral_contrast_retrieval,\n",
    "    'VGG19 Retrieval': vgg19_retrieval,\n",
    "    'ResNet Retrieval': resnet_retrieval,\n",
    "    'Tag-Based Retrieval': tag_based_retrieval_wrapper,  # New\n",
    "    'Early Fusion TF-IDF+BERT Retrieval': early_fusion_retrieval_wrapper,  # New\n",
    "    'Late Fusion MFCC+VGG19 Retrieval': late_fusion_retrieval_wrapper  # New\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc25395-2d7d-430b-a2e7-117d7c987bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 15. Define Evaluation Metrics\n",
    "# ================================\n",
    "\n",
    "def precision_at_k(retrieved_ids, relevant_ids, k=10):\n",
    "    \"\"\"\n",
    "    Computes Precision@k.\n",
    "\n",
    "    Parameters:\n",
    "    - retrieved_ids (list): List of retrieved track IDs.\n",
    "    - relevant_ids (list): List of relevant track IDs.\n",
    "    - k (int): Number of top tracks to consider.\n",
    "\n",
    "    Returns:\n",
    "    - float: Precision@k value.\n",
    "    \"\"\"\n",
    "    retrieved_set = set(retrieved_ids[:k])\n",
    "    relevant_set = set(relevant_ids)\n",
    "    precision = len(retrieved_set & relevant_set) / k\n",
    "    return precision\n",
    "\n",
    "def recall_at_k(retrieved_ids, relevant_ids, k=10):\n",
    "    \"\"\"\n",
    "    Computes Recall@k.\n",
    "\n",
    "    Parameters:\n",
    "    - retrieved_ids (list): List of retrieved track IDs.\n",
    "    - relevant_ids (list): List of relevant track IDs.\n",
    "    - k (int): Number of top tracks to consider.\n",
    "\n",
    "    Returns:\n",
    "    - float: Recall@k value.\n",
    "    \"\"\"\n",
    "    retrieved_set = set(retrieved_ids[:k])\n",
    "    relevant_set = set(relevant_ids)\n",
    "    recall = len(retrieved_set & relevant_set) / len(relevant_set) if relevant_set else 0\n",
    "    return recall\n",
    "\n",
    "def ndcg_at_k(retrieved_ids, relevant_ids, k=10):\n",
    "    \"\"\"\n",
    "    Computes NDCG@k.\n",
    "\n",
    "    Parameters:\n",
    "    - retrieved_ids (list): List of retrieved track IDs.\n",
    "    - relevant_ids (list): List of relevant track IDs.\n",
    "    - k (int): Number of top tracks to consider.\n",
    "\n",
    "    Returns:\n",
    "    - float: NDCG@k value.\n",
    "    \"\"\"\n",
    "    dcg = 0.0\n",
    "    for i, track_id in enumerate(retrieved_ids[:k]):\n",
    "        if track_id in relevant_ids:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "\n",
    "    # Ideal DCG\n",
    "    ideal_relevant = min(len(relevant_ids), k)\n",
    "    ideal_dcg = sum([1 / np.log2(i + 2) for i in range(ideal_relevant)])\n",
    "\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "def mrr_metric(retrieved_ids, relevant_ids):\n",
    "    \"\"\"\n",
    "    Computes Mean Reciprocal Rank (MRR).\n",
    "\n",
    "    Parameters:\n",
    "    - retrieved_ids (list): List of retrieved track IDs.\n",
    "    - relevant_ids (list): List of relevant track IDs.\n",
    "\n",
    "    Returns:\n",
    "    - float: MRR value.\n",
    "    \"\"\"\n",
    "    for rank, track_id in enumerate(retrieved_ids, start=1):\n",
    "        if track_id in relevant_ids:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "def compute_cov_at_n(all_retrieved_ids, catalog_df, N=10):\n",
    "    \"\"\"\n",
    "    Computes Coverage@N: Percentage of songs that appear in at least one retrieval list.\n",
    "\n",
    "    Parameters:\n",
    "    - all_retrieved_ids (list of lists): Each sublist contains retrieved IDs for a query.\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing all tracks with 'id'.\n",
    "    - N (int): Number of retrievals per query.\n",
    "\n",
    "    Returns:\n",
    "    - float: Coverage percentage.\n",
    "    \"\"\"\n",
    "    # Flatten the list of lists and consider only top N\n",
    "    flattened = [track_id for sublist in all_retrieved_ids for track_id in sublist[:N]]\n",
    "    unique_retrieved = set(flattened)\n",
    "    total_tracks = len(catalog_df)\n",
    "    coverage = (len(unique_retrieved) / total_tracks) * 100\n",
    "    return coverage\n",
    "\n",
    "def compute_div_at_n(all_retrieved_tags, N=10):\n",
    "    \"\"\"\n",
    "    Computes Diversity@N: Average number of unique tag occurrences among retrieved songs.\n",
    "\n",
    "    Parameters:\n",
    "    - all_retrieved_tags (list of lists): Each sublist contains tags of retrieved songs for a query.\n",
    "    - N (int): Number of retrievals per query.\n",
    "\n",
    "    Returns:\n",
    "    - float: Average diversity.\n",
    "    \"\"\"\n",
    "    diversity_scores = []\n",
    "    for tags in all_retrieved_tags:\n",
    "        # Consider only top N tags\n",
    "        top_n_tags = tags[:N]\n",
    "        unique_tags = set(top_n_tags)\n",
    "        diversity_scores.append(len(unique_tags))\n",
    "    average_diversity = np.mean(diversity_scores) if diversity_scores else 0\n",
    "    return average_diversity\n",
    "\n",
    "def compute_avg_pop_at_n(all_retrieved_popularity, N=10):\n",
    "    \"\"\"\n",
    "    Computes AvgPop@N: Average popularity of retrieved songs.\n",
    "\n",
    "    Parameters:\n",
    "    - all_retrieved_popularity (list of lists): Each sublist contains popularity scores of retrieved songs for a query.\n",
    "    - N (int): Number of retrievals per query.\n",
    "\n",
    "    Returns:\n",
    "    - float: Average popularity.\n",
    "    \"\"\"\n",
    "    avg_popularity_scores = []\n",
    "    for pops in all_retrieved_popularity:\n",
    "        top_n_pops = pops[:N]\n",
    "        avg_popularity_scores.append(np.mean(top_n_pops))\n",
    "    average_popularity = np.mean(avg_popularity_scores) if avg_popularity_scores else 0\n",
    "    return average_popularity\n",
    "\n",
    "def compute_genre_diversity(all_retrieved_genres, N=10):\n",
    "    \"\"\"\n",
    "    Computes Genre Diversity@N: Average number of unique genres among retrieved songs.\n",
    "\n",
    "    Parameters:\n",
    "    - all_retrieved_genres (list of lists): Each sublist contains genres of retrieved songs for a query.\n",
    "    - N (int): Number of retrievals per query.\n",
    "\n",
    "    Returns:\n",
    "    - float: Average genre diversity.\n",
    "    \"\"\"\n",
    "    diversity_scores = []\n",
    "    for genres in all_retrieved_genres:\n",
    "        # Consider only top N genres\n",
    "        top_n_genres = genres[:N]\n",
    "        unique_genres = set(top_n_genres)\n",
    "        diversity_scores.append(len(unique_genres))\n",
    "    average_diversity = np.mean(diversity_scores) if diversity_scores else 0\n",
    "    return average_diversity\n",
    "\n",
    "def compute_popularity_diversity(all_retrieved_popularity, N=10):\n",
    "    \"\"\"\n",
    "    Computes Popularity Diversity@N: Variance of popularity scores among retrieved songs.\n",
    "\n",
    "    Parameters:\n",
    "    - all_retrieved_popularity (list of lists): Each sublist contains popularity scores of retrieved songs for a query.\n",
    "    - N (int): Number of retrievals per query.\n",
    "\n",
    "    Returns:\n",
    "    - float: Average popularity diversity.\n",
    "    \"\"\"\n",
    "    diversity_scores = []\n",
    "    for pops in all_retrieved_popularity:\n",
    "        top_n_pops = pops[:N]\n",
    "        if len(top_n_pops) > 1:\n",
    "            diversity_scores.append(np.var(top_n_pops))\n",
    "        else:\n",
    "            diversity_scores.append(0)\n",
    "    average_diversity = np.mean(diversity_scores) if diversity_scores else 0\n",
    "    return average_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56530737-821c-48d8-9177-5c3b386cfb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 16. Define Evaluation Function\n",
    "# ================================\n",
    "\n",
    "def evaluate_retrieval_system(\n",
    "    catalog_df,\n",
    "    track_ids,\n",
    "    id_to_index,\n",
    "    retrieval_function,\n",
    "    feature_matrix=None,\n",
    "    N=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates a retrieval system, computing both accuracy and beyond-accuracy metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - catalog_df (pd.DataFrame): DataFrame containing all tracks with 'id', 'tags', 'popularity', 'top_genre', and 'genre'.\n",
    "    - track_ids (list): List of track IDs.\n",
    "    - id_to_index (dict): Mapping from track ID to index.\n",
    "    - retrieval_function (function): The specific retrieval function for the IR system.\n",
    "    - feature_matrix (csr_matrix, optional): Feature matrix used by the retrieval function.\n",
    "    - N (int): Number of tracks to retrieve per query.\n",
    "\n",
    "    Returns:\n",
    "    - metrics (dict): Dictionary containing all evaluation metrics.\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    mrrs = []\n",
    "\n",
    "    all_retrieved_ids = []\n",
    "    all_retrieved_tags = []\n",
    "    all_retrieved_genres = []\n",
    "    all_retrieved_popularity = []\n",
    "\n",
    "    total_queries = len(catalog_df)\n",
    "    processed_queries = 0\n",
    "\n",
    "    for index, query_track in catalog_df.iterrows():\n",
    "        query_id = query_track['id']\n",
    "        query_genre = query_track['top_genre']\n",
    "\n",
    "        if not query_genre:\n",
    "            continue\n",
    "\n",
    "        # Perform retrieval\n",
    "        if feature_matrix is not None:\n",
    "            retrieved_tracks = retrieval_function(\n",
    "                query_track_id=query_id,\n",
    "                id_to_index=id_to_index,\n",
    "                feature_matrix=feature_matrix,\n",
    "                track_ids=track_ids,\n",
    "                catalog_df=catalog_df,\n",
    "                N=N\n",
    "            )\n",
    "        else:\n",
    "            retrieved_tracks = retrieval_function(\n",
    "                query_track_id=query_id,\n",
    "                id_to_index=id_to_index,\n",
    "                feature_matrix=None,\n",
    "                track_ids=track_ids,\n",
    "                catalog_df=catalog_df,\n",
    "                N=N\n",
    "            )\n",
    "\n",
    "        if retrieved_tracks.empty:\n",
    "            continue\n",
    "\n",
    "        retrieved_ids = retrieved_tracks['id'].tolist()\n",
    "\n",
    "        # Extract tags, genres, and popularity\n",
    "        retrieved_subset = catalog_df[catalog_df['id'].isin(retrieved_ids)]\n",
    "        retrieved_tags = retrieved_subset['tags'].tolist()\n",
    "        retrieved_genres = retrieved_subset['genre'].tolist()\n",
    "        retrieved_popularity = retrieved_subset['popularity'].tolist()\n",
    "\n",
    "        # Compute accuracy metrics\n",
    "        relevant_ids = catalog_df[catalog_df['top_genre'] == query_genre]['id'].tolist()\n",
    "        p = precision_at_k(retrieved_ids, relevant_ids, k=N)\n",
    "        r = recall_at_k(retrieved_ids, relevant_ids, k=N)\n",
    "        ndcg = ndcg_at_k(retrieved_ids, relevant_ids, k=N)\n",
    "        rr = mrr_metric(retrieved_ids, relevant_ids)\n",
    "\n",
    "        precisions.append(p)\n",
    "        recalls.append(r)\n",
    "        ndcgs.append(ndcg)\n",
    "        mrrs.append(rr)\n",
    "\n",
    "        # Collect data for beyond-accuracy metrics\n",
    "        all_retrieved_ids.append(retrieved_ids)\n",
    "        # Flatten the list of tags and genres for each retrieved song\n",
    "        flattened_tags = [tag for sublist in retrieved_tags for tag in sublist]\n",
    "        flattened_genres = [genre for sublist in retrieved_genres for genre in sublist]\n",
    "        all_retrieved_tags.append(flattened_tags)\n",
    "        all_retrieved_genres.append(flattened_genres)\n",
    "        all_retrieved_popularity.append(retrieved_popularity)\n",
    "\n",
    "        processed_queries += 1\n",
    "        if processed_queries % 500 == 0:\n",
    "            print(f\"Processed {processed_queries}/{total_queries} queries\")\n",
    "\n",
    "    # Compute accuracy metrics\n",
    "    accuracy_metrics = {\n",
    "        'Precision@10': np.mean(precisions) if precisions else 0,\n",
    "        'Recall@10': np.mean(recalls) if recalls else 0,\n",
    "        'NDCG@10': np.mean(ndcgs) if ndcgs else 0,\n",
    "        'MRR': np.mean(mrrs) if mrrs else 0\n",
    "    }\n",
    "\n",
    "    # Compute beyond-accuracy metrics\n",
    "    coverage = compute_cov_at_n(all_retrieved_ids, catalog_df, N)\n",
    "    tag_diversity = compute_div_at_n(all_retrieved_tags, N)\n",
    "    genre_diversity = compute_genre_diversity(all_retrieved_genres, N)\n",
    "    popularity_diversity = compute_popularity_diversity(all_retrieved_popularity, N)\n",
    "    avg_popularity = compute_avg_pop_at_n(all_retrieved_popularity, N)\n",
    "\n",
    "    metrics = {\n",
    "        **accuracy_metrics,\n",
    "        'Coverage@10': coverage,\n",
    "        'Tag Diversity@10': tag_diversity,\n",
    "        'Genre Diversity@10': genre_diversity,\n",
    "        'Popularity Diversity@10': popularity_diversity,\n",
    "        'AvgPop@10': avg_popularity\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ================================\n",
    "# 17. Initialize Feature Matrices and Retrieval Systems\n",
    "# ================================\n",
    "\n",
    "# Initialize feature matrices for retrieval functions that require them\n",
    "feature_matrices = {\n",
    "    'TF-IDF Retrieval': tfidf_matrix,\n",
    "    'BERT Retrieval': bert_matrix,\n",
    "    'MFCC Retrieval': mfcc_bow_matrix,\n",
    "    'Spectral Contrast Retrieval': spectral_contrast_matrix,\n",
    "    'VGG19 Retrieval': vgg19_matrix,\n",
    "    'ResNet Retrieval': resnet_matrix,\n",
    "    'Tag-Based Retrieval': tag_matrix,  # New\n",
    "    'Early Fusion TF-IDF+BERT Retrieval': hstack([tfidf_matrix, bert_matrix]).tocsr(),  # New\n",
    "    # 'Late Fusion MFCC+VGG19 Retrieval' does not require a separate feature matrix as it uses existing ones\n",
    "}\n",
    "\n",
    "# Define all retrieval systems\n",
    "retrieval_systems = {\n",
    "    'Random Retrieval': random_retrieval,\n",
    "    'Tag-Based Retrieval': tag_based_retrieval_wrapper,  # New\n",
    "    'Early Fusion TF-IDF+BERT Retrieval': early_fusion_retrieval_wrapper,  # New\n",
    "    'Late Fusion MFCC+VGG19 Retrieval': late_fusion_retrieval_wrapper,  # New\n",
    "    'TF-IDF Retrieval': tfidf_retrieval,\n",
    "    'BERT Retrieval': bert_retrieval,\n",
    "    'MFCC Retrieval': mfcc_retrieval,\n",
    "    'Spectral Contrast Retrieval': spectral_contrast_retrieval,\n",
    "    'VGG19 Retrieval': vgg19_retrieval,\n",
    "    'ResNet Retrieval': resnet_retrieval\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# 18. Prepare Track IDs and Index Mapping\n",
    "# ================================\n",
    "\n",
    "track_ids = catalog_df['id'].tolist()\n",
    "id_to_index = {track_id: idx for idx, track_id in enumerate(track_ids)}\n",
    "\n",
    "# ================================\n",
    "# 19. Initialize a Dictionary to Store Results\n",
    "# ================================\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a04abb-8ac2-4c31-a2f5-0c64a11979ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Evaluation of Retrieval Systems...\n",
      "\n",
      "Evaluating Random Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for Random Retrieval:\n",
      "  Precision@10: 0.0399\n",
      "  Recall@10: 0.0020\n",
      "  NDCG@10: 0.0398\n",
      "  MRR: 0.0943\n",
      "  Coverage@10: 100.0000\n",
      "  Tag Diversity@10: 9.9600\n",
      "  Genre Diversity@10: 9.8419\n",
      "  Popularity Diversity@10: 187.7583\n",
      "  AvgPop@10: 34.9948\n",
      "--------------------------------------------------\n",
      "Evaluating Tag-Based Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for Tag-Based Retrieval:\n",
      "  Precision@10: 0.3519\n",
      "  Recall@10: 0.0837\n",
      "  NDCG@10: 0.3902\n",
      "  MRR: 0.6099\n",
      "  Coverage@10: 88.9666\n",
      "  Tag Diversity@10: 8.7904\n",
      "  Genre Diversity@10: 8.3320\n",
      "  Popularity Diversity@10: 149.2320\n",
      "  AvgPop@10: 38.1055\n",
      "--------------------------------------------------\n",
      "Evaluating Early Fusion TF-IDF+BERT Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for Early Fusion TF-IDF+BERT Retrieval:\n",
      "  Precision@10: 0.0711\n",
      "  Recall@10: 0.0053\n",
      "  NDCG@10: 0.0731\n",
      "  MRR: 0.1541\n",
      "  Coverage@10: 95.9013\n",
      "  Tag Diversity@10: 9.9289\n",
      "  Genre Diversity@10: 9.7688\n",
      "  Popularity Diversity@10: 185.5389\n",
      "  AvgPop@10: 36.3364\n",
      "--------------------------------------------------\n",
      "Evaluating Late Fusion MFCC+VGG19 Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for Late Fusion MFCC+VGG19 Retrieval:\n",
      "  Precision@10: 0.0946\n",
      "  Recall@10: 0.0081\n",
      "  NDCG@10: 0.1038\n",
      "  MRR: 0.2246\n",
      "  Coverage@10: 83.7218\n",
      "  Tag Diversity@10: 9.9289\n",
      "  Genre Diversity@10: 9.6902\n",
      "  Popularity Diversity@10: 173.5578\n",
      "  AvgPop@10: 37.7285\n",
      "--------------------------------------------------\n",
      "Evaluating TF-IDF Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for TF-IDF Retrieval:\n",
      "  Precision@10: 0.0600\n",
      "  Recall@10: 0.0037\n",
      "  NDCG@10: 0.0614\n",
      "  MRR: 0.1339\n",
      "  Coverage@10: 97.6496\n",
      "  Tag Diversity@10: 9.9417\n",
      "  Genre Diversity@10: 9.7815\n",
      "  Popularity Diversity@10: 189.5153\n",
      "  AvgPop@10: 36.1277\n",
      "--------------------------------------------------\n",
      "Evaluating BERT Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for BERT Retrieval:\n",
      "  Precision@10: 0.0842\n",
      "  Recall@10: 0.0073\n",
      "  NDCG@10: 0.0857\n",
      "  MRR: 0.1734\n",
      "  Coverage@10: 83.3528\n",
      "  Tag Diversity@10: 9.9033\n",
      "  Genre Diversity@10: 9.7077\n",
      "  Popularity Diversity@10: 181.1130\n",
      "  AvgPop@10: 37.3213\n",
      "--------------------------------------------------\n",
      "Evaluating MFCC Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for MFCC Retrieval:\n",
      "  Precision@10: 0.0927\n",
      "  Recall@10: 0.0081\n",
      "  NDCG@10: 0.0982\n",
      "  MRR: 0.2023\n",
      "  Coverage@10: 92.9099\n",
      "  Tag Diversity@10: 9.9130\n",
      "  Genre Diversity@10: 9.6855\n",
      "  Popularity Diversity@10: 164.8594\n",
      "  AvgPop@10: 35.9804\n",
      "--------------------------------------------------\n",
      "Evaluating Spectral Contrast Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for Spectral Contrast Retrieval:\n",
      "  Precision@10: 0.0633\n",
      "  Recall@10: 0.0052\n",
      "  NDCG@10: 0.0641\n",
      "  MRR: 0.1423\n",
      "  Coverage@10: 92.0746\n",
      "  Tag Diversity@10: 9.9200\n",
      "  Genre Diversity@10: 9.7595\n",
      "  Popularity Diversity@10: 176.1244\n",
      "  AvgPop@10: 35.9144\n",
      "--------------------------------------------------\n",
      "Evaluating VGG19 Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for VGG19 Retrieval:\n",
      "  Precision@10: 0.0731\n",
      "  Recall@10: 0.0063\n",
      "  NDCG@10: 0.0812\n",
      "  MRR: 0.1875\n",
      "  Coverage@10: 87.6457\n",
      "  Tag Diversity@10: 9.9460\n",
      "  Genre Diversity@10: 9.7607\n",
      "  Popularity Diversity@10: 166.8281\n",
      "  AvgPop@10: 36.1685\n",
      "--------------------------------------------------\n",
      "Evaluating ResNet Retrieval...\n",
      "Processed 500/5148 queries\n",
      "Processed 1000/5148 queries\n",
      "Processed 1500/5148 queries\n",
      "Processed 2000/5148 queries\n",
      "Processed 2500/5148 queries\n",
      "Processed 3000/5148 queries\n",
      "Processed 3500/5148 queries\n",
      "Processed 4000/5148 queries\n",
      "Processed 4500/5148 queries\n",
      "Processed 5000/5148 queries\n",
      "Metrics for ResNet Retrieval:\n",
      "  Precision@10: 0.0786\n",
      "  Recall@10: 0.0060\n",
      "  NDCG@10: 0.0878\n",
      "  MRR: 0.2018\n",
      "  Coverage@10: 82.8671\n",
      "  Tag Diversity@10: 9.9419\n",
      "  Genre Diversity@10: 9.7492\n",
      "  Popularity Diversity@10: 167.7420\n",
      "  AvgPop@10: 35.2677\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Evaluation Results:\n",
      "                                    Precision@10  Recall@10   NDCG@10  \\\n",
      "Random Retrieval                        0.039860   0.001997  0.039821   \n",
      "Tag-Based Retrieval                     0.351865   0.083709  0.390184   \n",
      "Early Fusion TF-IDF+BERT Retrieval      0.071115   0.005337  0.073101   \n",
      "Late Fusion MFCC+VGG19 Retrieval        0.094639   0.008080  0.103793   \n",
      "TF-IDF Retrieval                        0.060043   0.003678  0.061351   \n",
      "BERT Retrieval                          0.084227   0.007263  0.085740   \n",
      "MFCC Retrieval                          0.092735   0.008079  0.098159   \n",
      "Spectral Contrast Retrieval             0.063287   0.005164  0.064119   \n",
      "VGG19 Retrieval                         0.073116   0.006297  0.081157   \n",
      "ResNet Retrieval                        0.078555   0.006001  0.087762   \n",
      "\n",
      "                                         MRR  Coverage@10  Tag Diversity@10  \\\n",
      "Random Retrieval                    0.094348   100.000000          9.959984   \n",
      "Tag-Based Retrieval                 0.609858    88.966589          8.790404   \n",
      "Early Fusion TF-IDF+BERT Retrieval  0.154135    95.901321          9.928904   \n",
      "Late Fusion MFCC+VGG19 Retrieval    0.224612    83.721834          9.928904   \n",
      "TF-IDF Retrieval                    0.133858    97.649573          9.941725   \n",
      "BERT Retrieval                      0.173357    83.352758          9.903263   \n",
      "MFCC Retrieval                      0.202263    92.909868          9.912976   \n",
      "Spectral Contrast Retrieval         0.142304    92.074592          9.919969   \n",
      "VGG19 Retrieval                     0.187502    87.645688          9.945998   \n",
      "ResNet Retrieval                    0.201793    82.867133          9.941919   \n",
      "\n",
      "                                    Genre Diversity@10  \\\n",
      "Random Retrieval                              9.841880   \n",
      "Tag-Based Retrieval                           8.331974   \n",
      "Early Fusion TF-IDF+BERT Retrieval            9.768842   \n",
      "Late Fusion MFCC+VGG19 Retrieval              9.690171   \n",
      "TF-IDF Retrieval                              9.781469   \n",
      "BERT Retrieval                                9.707653   \n",
      "MFCC Retrieval                                9.685509   \n",
      "Spectral Contrast Retrieval                   9.759518   \n",
      "VGG19 Retrieval                               9.760684   \n",
      "ResNet Retrieval                              9.749223   \n",
      "\n",
      "                                    Popularity Diversity@10  AvgPop@10  \n",
      "Random Retrieval                                 187.758256  34.994833  \n",
      "Tag-Based Retrieval                              149.231956  38.105458  \n",
      "Early Fusion TF-IDF+BERT Retrieval               185.538949  36.336422  \n",
      "Late Fusion MFCC+VGG19 Retrieval                 173.557795  37.728535  \n",
      "TF-IDF Retrieval                                 189.515332  36.127681  \n",
      "BERT Retrieval                                   181.112988  37.321251  \n",
      "MFCC Retrieval                                   164.859404  35.980439  \n",
      "Spectral Contrast Retrieval                      176.124423  35.914355  \n",
      "VGG19 Retrieval                                  166.828112  36.168493  \n",
      "ResNet Retrieval                                 167.742026  35.267657  \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 20. Evaluate All Retrieval Systems\n",
    "# ================================\n",
    "\n",
    "print(\"\\nStarting Evaluation of Retrieval Systems...\\n\")\n",
    "\n",
    "for name, func in retrieval_systems.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    if name == 'Random Retrieval':\n",
    "        # Random Retrieval does not require a feature matrix\n",
    "        metrics = evaluate_retrieval_system(\n",
    "            catalog_df=catalog_df,\n",
    "            track_ids=track_ids,\n",
    "            id_to_index=id_to_index,\n",
    "            retrieval_function=func,\n",
    "            feature_matrix=None,\n",
    "            N=10\n",
    "        )\n",
    "    elif name == 'Early Fusion TF-IDF+BERT Retrieval':\n",
    "        # Early Fusion uses the combined feature matrix\n",
    "        feature_matrix = feature_matrices.get(name)\n",
    "        metrics = evaluate_retrieval_system(\n",
    "            catalog_df=catalog_df,\n",
    "            track_ids=track_ids,\n",
    "            id_to_index=id_to_index,\n",
    "            retrieval_function=func,\n",
    "            feature_matrix=feature_matrix,\n",
    "            N=10\n",
    "        )\n",
    "    elif name == 'Late Fusion MFCC+VGG19 Retrieval':\n",
    "        # Late Fusion handles its own feature matrices internally\n",
    "        metrics = evaluate_retrieval_system(\n",
    "            catalog_df=catalog_df,\n",
    "            track_ids=track_ids,\n",
    "            id_to_index=id_to_index,\n",
    "            retrieval_function=func,\n",
    "            feature_matrix=None,  # Feature matrices are handled inside the retrieval function\n",
    "            N=10\n",
    "        )\n",
    "    else:\n",
    "        # Other retrieval systems that require a feature matrix\n",
    "        feature_matrix = feature_matrices.get(name)\n",
    "        if feature_matrix is None:\n",
    "            print(f\"Error: Feature matrix for '{name}' not found.\")\n",
    "            continue\n",
    "        metrics = evaluate_retrieval_system(\n",
    "            catalog_df=catalog_df,\n",
    "            track_ids=track_ids,\n",
    "            id_to_index=id_to_index,\n",
    "            retrieval_function=func,\n",
    "            feature_matrix=feature_matrix,\n",
    "            N=10\n",
    "        )\n",
    "    results[name] = metrics\n",
    "    print(f\"Metrics for {name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ================================\n",
    "# 21. Compile and View Results\n",
    "# ================================\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cb1de8d-bf4f-4bea-a509-05785aff01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 22. Visualization of Results\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure Seaborn aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "# Define plot configurations\n",
    "plot_configs = [\n",
    "    {\n",
    "        'x': 'Coverage@10',\n",
    "        'y': 'NDCG@10',\n",
    "        'title': 'NDCG@10 vs Coverage@10',\n",
    "        'xlabel': 'Coverage@10 (%)',\n",
    "        'ylabel': 'NDCG@10',\n",
    "        'filename': 'ndcg_vs_coverage.png'\n",
    "    },\n",
    "    {\n",
    "        'x': 'Tag Diversity@10',\n",
    "        'y': 'NDCG@10',\n",
    "        'title': 'NDCG@10 vs Tag Diversity@10',\n",
    "        'xlabel': 'Tag Diversity@10',\n",
    "        'ylabel': 'NDCG@10',\n",
    "        'filename': 'ndcg_vs_tag_diversity.png'\n",
    "    },\n",
    "    {\n",
    "        'x': 'Genre Diversity@10',\n",
    "        'y': 'NDCG@10',\n",
    "        'title': 'NDCG@10 vs Genre Diversity@10',\n",
    "        'xlabel': 'Genre Diversity@10',\n",
    "        'ylabel': 'NDCG@10',\n",
    "        'filename': 'ndcg_vs_genre_diversity.png'\n",
    "    },\n",
    "    {\n",
    "        'x': 'Popularity Diversity@10',\n",
    "        'y': 'NDCG@10',\n",
    "        'title': 'NDCG@10 vs Popularity Diversity@10',\n",
    "        'xlabel': 'Popularity Diversity@10',\n",
    "        'ylabel': 'NDCG@10',\n",
    "        'filename': 'ndcg_vs_popularity_diversity.png'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Ensure the 'plots' directory exists\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Generate and save each plot\n",
    "for config in plot_configs:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        data=results_reset,\n",
    "        x=config['x'],\n",
    "        y=config['y'],\n",
    "        hue='Retrieval_System',\n",
    "        s=100,\n",
    "        palette='deep'\n",
    "    )\n",
    "    plt.title(config['title'], fontsize=16)\n",
    "    plt.xlabel(config['xlabel'], fontsize=14)\n",
    "    plt.ylabel(config['ylabel'], fontsize=14)\n",
    "    plt.legend(title='IR System', fontsize=12, title_fontsize=14, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{config['filename']}\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549fc99a-3b1c-407f-834f-cb6654ef54d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
